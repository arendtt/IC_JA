/genetica_1/Genotipagem_INPD_Broad2019/PGC_NIMH_Salum_PTSD_GSA-MD_v1_3/RP-1194/processamento_inpd2019/proc_inicial_5548inds_dez19/

### IDs estao trocados como enviamos para o Broad. Precisa atuazliar IDs

# Pegar dados do cerebro
scp escience@172.23.16.216:/genetica_1/Genotipagem_INPD_Broad2019/PGC_NIMH_Salum_PTSD_GSA-MD_v1_3/RP-1194/processamento_inpd2019/proc_inicial_5548inds_dez19/INPD_GenoBroad19_11.vcf.gz ./IC_JA/
senha: escience

scp i123@172.23.16.216:/media/i123/genetica_1/Genotipagem_INPD_Broad2019/PGC_NIMH_Salum_PTSD_GSA-MD_v1_3/RP-1194/processamento_inpd2019/proc_inicial_5548inds_dez19/INPD_GenoBroad19_10.vcf.gz ./julia.arendt/IC_JA/
senha: 123456

### (scp quem praonde)

# Indexar o vcf. Imagina que esse arquivo é gigantesco, "indexar" em genética significa que o programinha vai criar um index para facilitar encontrar as infos mais rapidamente no arquivo. Tipo um livro
for i in {1..12}; do ./gatk IndexFeatureFile -I /home/julia.arendt/IC_JA/INPD_GenoBroad19_${i}.vcf.gz ; done
for i in {1..12}; do tabix -p vcf INPD_GenoBroad19_${i}.vcf.gz; done
 
### Cuidado com os caminhos  

# Separar as informações que são importantes para extrair o dado de CNV. 
for i in {1..12}; do ./gatk VariantsToTable -V /home/julia.arendt/IC_JA/INPD_GenoBroad19_${i}.vcf.gz -F ID -F CHROM -F POS -GF BAF -GF LRR --show-filtered -O INPD_CNVs_${i}.vcf; done

# trocando cabeçalhos (isso pode ser feito de uma forma mais bonita)
for i in {1..12}; do sed 's/BAF/B Allele Freq/g' INPD_CNVs_${i}.vcf > INPD_CNVs_${i}.baf ; done
for i in {1..12}; do sed 's/LRR/Log R Ratio/g' INPD_CNVs_${i}.baf > INPD_CNVs_${i}.baf_lrr ; done


## perl ~/PennCNV-1.0.5/compile_pfb.pl 

### Só da primeira vez

for i in {1..12}; do perl ~/IC_JA/PennCNV-1.0.5/kcolumn.pl INPD_CNVs_${i}.baf_lrr split 2 -tab -head 3 -name -out INPD_${i}_ref ; done

for i in {1..12}; do ls INPD_${i}_ref* > IDs_INPD_${i} ; done

# Mudar cabeçalhos dos *_ref* ## Perguntar pro Marquinhos (?)

for i in {1..12}; do sed 's/INPD_${i}_ref.//g' IDs_INPD_${i} > lista_files_INPD_${i} ; done

# mudar cabecalho só do primeiro arquivo, de ID para Name, de POS para Position e de CHROM para Chr
# Para sair do vi salvando: ESC ":x"
# Para sair do vi sem salvar: ESC ":q!"

#vi INPD_11_ref.201904760146_R07C01
#for i in {11..11}; do perl /home/julia.arendt/IC_JA/PennCNV-1.0.5/compile_pfb.pl -list PFB_novo.txt -output INPD.pfb ; done #PFB_novo.txt é o arquivo sem parentes, antes era IDs_ParaPFB
# reverter cabecalho para o original
#vi INPD_11_ref.201904760146_R07C01

# Daqui pra baixo você vai preciar mudar os radicais dos arquivos e com os dados da illumina
# Aqui a gente precisava mudar o cabeçalho de todos os arquivos (500 ) mas achamos mais facil mudar a chamada no script, ao inves de procurar por Name, ele procura por ID.
# sed 's/Name/ID/g; s/Chr/CHROM/g; s/Position/POS/g' detect_cnv.pl > detect_cnv_header.pl

## Na pasta gatk 

for i in {10..10}; do detect_cnv_header.pl -test -hmm /home/julia.arendt/IC_JA/PennCNV-1.0.5/lib/hhall.hmm -pfb /home/julia.arendt/IC_JA/gatk-4.2.0.0/INPD.pfb -list /home/julia.arendt/IC_JA/gatk-4.2.0.0/IDs_INPD_10 -log INPD10.log -out INPD10.rawcnv; done



PennCNV - controle de qualidade (Malú)

# 1. QC por amostra
for i in {1..12}; do ./filter_cnv.pl ~/IC_JA/gatk-4.2.0.0/INPD_${i}.rawcnv -qclogfile ~/IC_JA/gatk-4.2.0.0/INPD_${i}.log -qclrrsd 0.3 -qcpassout INPD_${i}.qcpass -qcsumout INPD_${i}.qcsum -qcnumcnv 100 -out INPD_${i}.goodcnv ; done


## No R, usando o arquivo .qcsum. Visualização da distribuição de CNVs por pacientes (não fiz!)
eshg <- read.table("~/caminho/arquivoquevcquerchamar.goodcnv", h=T) 
head(eshg)
barplot(eshg$LRR_SD, ylim = c(0, 0.3), xlab = "Pacientes", ylab = "LRR_SD", main = "Sample QC") 
barplot(eshg$NumCNV, ylim = c(0,30), main = "CNVs por amostra", xlab = "Pacientes", ylab = "Número de CNVs" )


# 2. Remover regiões ruins

## Centroméricas
### Arquivo centromerescerto.txt achado na internet
# awk '{print $1":"$2"-"$3}' centromere.txt > centromerescerto.txt

for i in {1..12}; do ./scan_region.pl INPD_${i}.goodcnv centromerescerto.txt -minqueryfrac 0.5 > INPD_${i}_cnvcall.cen ; done
for i in {1..12}; do fgrep -v -f INPD_${i}_cnvcall.cen INPD_${i}.goodcnv > INPD_${i}_cen.clean ; done


## Teloméricas:
### Arquivo telomeres.txt feito com 10000bp de diferença - Genome Browser

for i in {1..12}; do ./scan_region.pl INPD_${i}_cen.clean telomeres.txt -minqueryfrac 0.5 > INPD_${i}_cnvcall.tel ; done
for i in {1..12}; do fgrep -v -f INPD_${i}_cnvcall.tel INPD_${i}_cen.clean > INPD_${i}_cen_tel.clean ; done


## Duplicações segmentais, exceto 22q11.2: 
### Arquivo segdup_hg19certo.bed feito em https://genome.ucsc.edu/cgi-bin/hgTables (group: Repeats; tracks: Segmental Dups; table: genomicSuperDups)
# tail -n +2 segdup.txt | awk '{print $2,$3, $4}'| sed 's/ /\t/g' > segdup_hg19.bed
# awk '{print $1":"$2"-"$3}' segdup_hg19.bed > segdup_hg19certo.bed

for i in {1..12}; do ./scan_region.pl INPD_${i}_cen_tel.clean segdup_hg19certo.bed -minqueryfrac 0.5 > INPD_${i}_cnvcall.segdup ; done
for i in {1..12}; do fgrep -v -f INPD_${i}_cnvcall.segdup INPD_${i}_cen_tel.clean > INPD_${i}_cen_tel_segdup.clean ; done


## Regiões de imunoglobulinas:
### Fiz o arquivo immuno_hg19 com as seguintes regiões: 
    # chr22:22385572-23265082
    # chr14:105994256-107281230
    # chr2:89156874-89630187
    # chr14:22090057-23021097

for i in {1..12}; do ./scan_region.pl INPD_${i}_cen_tel_segdup.clean immuno_hg19 -minqueryfrac 0.5 > INPD_${i}_cnvcall.immuno; done 
for i in {1..12}; do fgrep -v -f INPD_${i}_cnvcall.immuno INPD_${i}_cen_tel_segdup.clean > INPD_${i}_cen_tel_segdup_immuno.clean; done


# 3. Merge
for i in {1..12} ./clean_cnv.pl -signalfile ~/IC_JA/gatk-4.2.0.0/INPD.pfb --fraction 0.5 combineseg INPD_${i}_cen_tel_segdup.clean > INPD_${i}_cen_tel_segdup_merged.clean ; done

#signalfile: a file that contains Chr and Position for SNPs/markers
#Observação: fraction 0.5/50% (default)


# 4. Mínimo de sondas:

## Deleções (20 sondas):
for i in {1..12}; do ./filter_cnv.pl -numsnp 10 -length 1k -type del INPD_${i}_cen_tel_segdup_merged.clean -output INPD_${i}_del.clean ; done


## Duplicações (20 sondas):
for i in {1..12}; do ./filter_cnv.pl -numsnp 10 -length 1k -type dup INPD_${i}_cen_tel_segdup_merged.clean -output INPD_${i}_dup.clean ; done


# 5. Juntar arquivos com deleções e duplicações:
for i in {1..12}; do cat INPD_${i}_del.clean INPD_${i}_dup.clean > INPD_${i}_del_dup.clean ; done


# 6. Ordenar pela primeira coluna 
for i in {1..12} sort -rk 1 INPD_${i}_del_dup.clean > INPD_deldup_${i}.ordenado ; done


